{
    "meeting_id": "2d0ce6c0-35ca-43d2-bac7-6cc1038b287c",
    "meeting_title": "Untitled Meeting",
    "timestamp": "2025-07-19T22:53:41.789243",
    "transcript": "Hello, everyone. My name is Tom and today I have with me two of my awesome colleagues and we can start by getting them introduced. Sameer. Hey, everyone. This is Sameer and I help in articulating the value provided by our open platform and the plethora of use cases that can be supported. Let's go to the next one. Hi, everyone. My name is Will and I talk about the how. How do we use the APIs? How do we integrate them? How do we deploy them go live in our production applications? Awesome. Thanks, guys. Today, the topic is about RingCentral's AI APIs around conversational intelligence. So let's get started. Question for Sameer. AI is a very highly used acronym over the past 45 years, especially. How do you understand it in context of conversations? What capabilities does it bring and how easy is it to use? Very well, Tom, you hit the nail on the head. Yes, AI is a very, very highly used acronym for last, I would say, five to six years. But when you think about AI in context of conversations, like the first thing that comes to the mind is speech to text capability or text to speech capabilities. But I think it's much, much beyond that. For example, you can do a lot of interaction analysis, sentiment analysis and emotion analysis with these APIs that we offer. It means if you are in a contact center kind of a use case where a supervisor needs to understand what kind of calls are coming in from all the people around the world to understand the sentiment level, they can simply have a pointer zero to five to figure out the calls coming in, fall in what range to understand the sentiment of those calls. That's one of the biggest, biggest powers that we give through our AI APIs. Wow, that is so interesting. Next question I have here is for Will. What are the different set of APIs that we support today? And how can you throw some light on the three of the top most used conversational intelligence API use cases across our portfolio of API products? Yeah, great question. We support basically APIs at two categories. One, they're audio APIs and the other set of APIs are based on text. And the three most popular APIs are you can say the speech to text because even audio gets converted into text and then the AI engine gives you the transcript of that. And it can give you transcript with punctuation such as comma so that you can turn it into a report. Another API very popular is the speaker diarheization API. So, for example, there are multiple people here in this meeting and the API will tell you which speaker is speaking at which point of time, who spoke what essentially. And then there is another API that does speaker identification. This is similar to speaker diarheization API. It detects who's speaking and if the AI model has been trained by the speaker's voice, it can tell you who the person is if you provide a label such as the name of the person. And then it will tell you, for example, Will is speaking at this time. Otherwise, it will just say person A, person B, person C. That's great, Will. Samir, Will, thank you so much again for explaining the whys and the hows of RingCentral's open platform and specifically our intelligent APIs. This program's in beta right now. We'll soon be working toward releasing it generally available to the public. So, please stay tuned and we look forward to getting some feedback from you.\n",
    "summary": "The meeting was held by Tom, Sameer, and Will to discuss RingCentral's AI APIs around conversational intelligence. Sameer clarified that the use of AI in conversations extends beyond speech-to-text and text-to-speech capabilities, including interaction, sentiment, and emotion analysis. This allows contact centers to gauge the sentiment of incoming calls via a scoring system. Will on the other hand, explained that they support both audio and text-based APIs. The most popular APIs are the speech-to-text, speaker diarization, and speaker identification APIs. The speakers also discussed the current beta status of their program, with plans to release it to the public soon. They encouraged attendees to provide feedback following the release.",
    "action_items": [],
    "decisions": []
}